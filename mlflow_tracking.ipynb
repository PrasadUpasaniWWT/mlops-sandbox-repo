{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8c0265-3b5f-45b1-9685-f1de89201e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import os\n",
    "from mlflow.models.signature import infer_signature\n",
    "import json\n",
    "\n",
    "def track_mlflow_experiment(\n",
    "    model,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    params: dict,\n",
    "    metrics: dict,\n",
    "    experiment_name: str,\n",
    "    model_name: str,\n",
    "    run_name: str = None,\n",
    "    tags: dict = None,\n",
    "    artifacts: dict = None,\n",
    "    log_model: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    Track model training in SageMaker + MLflow hosted environment.\n",
    "\n",
    "    Args:\n",
    "        model: Trained model object (e.g. scikit-learn, XGBoost).\n",
    "        X_train, y_train, X_test, y_test: Data used.\n",
    "        params (dict): Model hyperparameters.\n",
    "        metrics (dict): Evaluation metrics (accuracy, F1, etc.).\n",
    "        experiment_name (str): MLflow experiment name.\n",
    "        model_name (str): For model registry.\n",
    "        run_name (str): Optional run name.\n",
    "        tags (dict): Optional tags (e.g. {\"env\": \"dev\"}).\n",
    "        artifacts (dict): Optional artifacts to log: {name: path}.\n",
    "        log_model (bool): Whether to log the model.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set experiment\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "\n",
    "        # Log Params\n",
    "        for key, val in params.items():\n",
    "            mlflow.log_param(key, val)\n",
    "\n",
    "        # Log Metrics\n",
    "        for key, val in metrics.items():\n",
    "            mlflow.log_metric(key, val)\n",
    "\n",
    "        # Log Tags\n",
    "        if tags:\n",
    "            for key, val in tags.items():\n",
    "                mlflow.set_tag(key, val)\n",
    "\n",
    "        # Infer signature from test data\n",
    "        signature = infer_signature(X_test, model.predict(X_test))\n",
    "\n",
    "        # Log Model\n",
    "        if log_model:\n",
    "            mlflow.sklearn.log_model(\n",
    "                model,\n",
    "                artifact_path=\"model\",\n",
    "                signature=signature,\n",
    "                input_example=X_test[:5],\n",
    "                registered_model_name=model_name\n",
    "            )\n",
    "\n",
    "        # Log Artifacts\n",
    "        if artifacts:\n",
    "            for key, path in artifacts.items():\n",
    "                if os.path.exists(path):\n",
    "                    mlflow.log_artifact(path, artifact_path=key)\n",
    "\n",
    "        # Log environment (requirements.txt)\n",
    "        if os.path.exists(\"requirements.txt\"):\n",
    "            mlflow.log_artifact(\"requirements.txt\")\n",
    "\n",
    "        # Log notebook or script\n",
    "        for fname in [\"train.py\", \"notebook.ipynb\", \"main.py\"]:\n",
    "            if os.path.exists(fname):\n",
    "                mlflow.log_artifact(fname)\n",
    "\n",
    "        print(\"âœ… Logged to MLflow successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dead478-a4c1-4bb4-ad47-fcc7aa4b5881",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=5)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "params = model.get_params()\n",
    "metrics = {\"accuracy\": accuracy_score(y_test, y_pred)}\n",
    "\n",
    "track_mlflow_experiment(\n",
    "    model=model,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    params=params,\n",
    "    metrics=metrics,\n",
    "    experiment_name=\"sagemaker-experiment\",\n",
    "    model_name=\"rf-prod-model\",\n",
    "    run_name=\"baseline_rf_sagemaker\",\n",
    "    tags={\"user\": \"prasad\", \"project\": \"churn\"},\n",
    "    artifacts={\"plots\": \"output/roc_curve.png\"}\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
